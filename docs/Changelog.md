# s3dlio Changelog

## Version 0.7.9 - Python API Stability & Multi-Backend Streaming (September 2, 2025)

This release delivers a **stable, production-ready Python API** with fully functional streaming operations across multiple storage backends and comprehensive checkpoint system. Focus on reliability and actual functionality over feature claims.

### üéØ **Core Achievements**

#### ‚úÖ **Universal Streaming API (PRODUCTION READY)**
- **Multi-Backend Support**: Streaming writers working flawlessly across:
  - Filesystem (`file://` URIs)
  - Azure Blob Storage (`az://` URIs) 
  - Direct I/O filesystem with O_DIRECT support
- **Synchronous Python API**: Fixed "no running event loop" errors - all functions callable from normal Python code
- **PyWriterOptions & PyObjectWriter**: Complete configuration and writer classes with proper error handling
- **Production Tested**: Comprehensive validation across all backends with real data

#### ‚úÖ **Checkpoint System (FULLY FUNCTIONAL)**
- **PyCheckpointStore**: Complete save/load cycle with automatic file management
- **Multi-Backend Storage**: Works with `file://` URIs for local/network storage
- **Data Integrity**: Robust serialization/deserialization with error handling
- **Compression Support**: Optional zstd compression in checkpoint system
- **Version Management**: Proper checkpoint versioning and metadata handling

#### ‚úÖ **Python API Infrastructure**
- **Modular Architecture**: Clean separation of core, AI/ML, and advanced features
- **Error Handling**: Comprehensive error propagation and user-friendly messages
- **Type Safety**: Proper PyO3 integration with safe memory management
- **Documentation**: Accurate function signatures and usage patterns

### üîß **Technical Implementation**

#### **Fixed Async Integration**
```python
# This now works perfectly - no async/await required
import s3dlio

options = s3dlio.PyWriterOptions()
writer = s3dlio.create_filesystem_writer('file:///tmp/data.txt', options)
writer.write_chunk(b'Hello World!')
stats = writer.finalize()  # Returns (bytes_written, compressed_bytes)
```

#### **Multi-Backend Streaming**
```python
# All backends work identically
fs_writer = s3dlio.create_filesystem_writer('file:///tmp/data.txt', options)
azure_writer = s3dlio.create_azure_writer('az://account/container/data.txt', options) 
direct_writer = s3dlio.create_direct_filesystem_writer('file:///tmp/direct.txt', options)
```

#### **Checkpoint Operations**
```python
# Full checkpoint functionality
store = s3dlio.PyCheckpointStore('file:///tmp/checkpoints')
store.save(epoch=1, step=0, name='model', data=model_bytes, metadata=None)
loaded_data = store.load_latest()
```

### üö´ **Honest Scope Limitations**

#### **S3-Focused Core Operations**
- `get()`, `put()`, `list()`, `delete()` functions require S3 URIs and credentials
- `PyS3Dataset`, `PyVecDataset` designed for S3-based workflows
- `MultipartUploadWriter` is S3-specific for large uploads

#### **No Public/Legacy API Split**
- Abandoned the confusing "public" vs "legacy" API distinction from 0.7.4-0.7.8
- Single, coherent API surface focused on working functionality
- Clean interfaces without artificial versioning complexity

### üìä **What Actually Works vs Previous Claims**

#### ‚úÖ **Delivered & Working**
- Streaming API across File/Azure/Direct I/O backends
- Checkpoint system with compression
- Python-Rust data exchange
- Proper error handling and memory management
- O_DIRECT support for high-performance I/O

#### ‚ùå **Removed Overreaching Claims**
- Universal backend support for all operations (only streaming & checkpoints are universal)
- Complete NumPy integration (has compatibility issues)
- "Zero-copy" everywhere (limited to specific scenarios)
- Complex public/legacy API architecture

### üéØ **Production Readiness**

This release focuses on **proven, tested functionality** rather than aspirational features:

- ‚úÖ **Streaming Writers**: Battle-tested across all backends
- ‚úÖ **Checkpoint System**: Reliable save/load with compression
- ‚úÖ **Python Integration**: Stable PyO3 bindings with proper error handling
- ‚úÖ **Multi-Backend**: File, Azure, Direct I/O all working
- ‚ö†Ô∏è **S3 Operations**: Available but require AWS credentials
- ‚ö†Ô∏è **AI/ML Datasets**: Complex usage patterns, primarily S3-focused

### üîÑ **Migration from 0.7.8**

- No breaking changes for working functionality
- Streaming API significantly more reliable (no event loop errors)
- Simplified API surface (removed public/legacy split)
- Enhanced error messages and debugging support

---

## Previous Versions

*[Previous changelog entries for versions 0.7.8 and earlier contained aspirational features and architectural decisions that were subsequently revised. The above represents the current stable functionality.]*
